\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[final]{neurips_2018}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

%opening
\title{Online influence maximization with different propagation models}
\author{Paul Chevalier, Tangi Hetet}

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

\section{Presentation of the algorithm}

\begin{algorithm}
\caption{Node selection}\label{oracle}
\hspace*{\algorithmicindent} \textbf{Input: } $G$, $k$, $\theta$\\
\hspace*{\algorithmicindent} \textbf{Output: } a set $S_k^*$ of $k$ nodes from $G$
\begin{algorithmic}[1]
\State $\text{Initialize a set } \mathcal{R} = \emptyset$
\State Generate $\theta$ random RR sets and insert them into $\mathcal{R}$
\State Initialize a node set $S_k^* = \emptyset$
\For {$j = 1$ to $k$}
\State Identify the node $v_j$ that covers the most RR sets in $\mathcal{R}$.
\State Add $v_j$ into $S_k^*$
\State Remove from $\mathcal{R}$ all RR sets that are covered by $v_j$
\EndFor
\Return $S_k^*$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{$\text{KPT}^*$ estimation}\label{kptestimation}
\hspace*{\algorithmicindent} \textbf{Input: } $G$, $k$\\
\hspace*{\algorithmicindent} \textbf{Output: } estimated $\text{KPT}^*$
\begin{algorithmic}[1]
\For {$i=1$ to $\log_2 n - 1$}
\State Let $c_i = (6l\log n + 6\log\log_2 n)\times 2^i$
\State Let $s = 0$
\For {$k=1$ to $c_i$}
\State Generate a random RR set $\mathcal{R}$
\State $\kappa(R) = 1 - \left(1-\frac{w(\mathcal{R})}{m}\right)^k$
\State $s = s + \kappa(\mathcal{R})$
\EndFor
\If {$s/c_i > 1/2^i$}
\Return $\text{KPT}^* = ns/(2c_i)$
\Return $\text{KPT}^* = 1$
\EndIf
\EndFor
\end{algorithmic}
\end{algorithm}


\begin{algorithm}
\caption{CUCB with computation oracle}\label{cucb}
\hspace*{\algorithmicindent} \textbf{Input: } $m$, Oracle
\begin{algorithmic}[1]
\State For each arm $i$, $T_i = 0$ (maintain the total number of times arm $i$ is played so far)
\State For each arm $i$, $\hat{\mu}_i = 1$ (maintain the empirical mean of $X_i$)
\For {t = 1, 2, 3, ...}
\State For each arm $i\in[m]$, $\rho_i = \sqrt{\frac{3\log t}{2T_i}}$ (the confidence radius $\rho_i = +\infty$ if $T_i = 0$)
\State For each arm $i\in[m]$, $\bar{\mu}_i = \min\{\hat{\mu}_i + \rho_i, 1\}$ (the upper confidence bound)
\State $S = \text{Oracle}(\bar{\mu}_1, ..., \bar{\mu}_m)$
\State Play action $S$, which triggers a set $\tau \subseteq[m]$ of base arms with feedback $X_i^{(t)}, s, i\in\tau$
\State For every $i\in\tau$, update $T_i$ and $\hat{\mu}_i$: $T_i = T_i+1$, $\hat{\mu}_i = \hat{\mu}_i + (X_i^{(t)} - \hat{\mu}_i) / T_i$
\EndFor
\end{algorithmic}
\end{algorithm}

\section{Experiments}

\section{Conclusion}

\end{document}
